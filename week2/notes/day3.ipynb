{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Building AI Chatbots: Mastering Gradio for Customer Support Assistants\n",
    "\n",
    "### Summary\n",
    "\n",
    "This session focuses on building chat UIs and AI customer support assistants (chatbots). It covers how LLMs excel at conversational interfaces, maintaining context, and utilizing prompts effectively. The session emphasizes the importance of system prompts, context, and multi-shot prompting to guide the chatbot's behavior.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ’¬ Building chat UIs and AI customer support assistants using LLMs.\n",
    "- ğŸ”„ LLMs maintain conversation context by feeding the entire history back into each prompt.\n",
    "- ğŸ­ Chatbots can adopt specific personas and subject matter expertise.\n",
    "- ğŸ“ System prompts set the tone and rules for the conversation.\n",
    "- ğŸ“š Contextual prompts add specific information to guide the LLM's responses.\n",
    "- ğŸ’¡ Multi-shot prompting uses examples to shape the LLM's behavior at inference time.\n",
    "- ğŸ’» Building a functional chatbot interface within a single lesson.\n",
    "\n",
    "# Day 3 - Build a Conversational AI Chatbot with OpenAI & Gradio: Step-by-Step\n",
    "\n",
    "### Summary\n",
    "\n",
    "This session demonstrates how to build a simple chatbot using OpenAI and Gradio. It explains the structure of prompt messages, the function required for Gradio's chat interface, and how conversation history is managed. It also clarifies how OpenAI handles message structures and converts them into tokens for the LLM.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ¤– Building a chatbot UI using OpenAI and Gradio's `chatinterface`.\n",
    "- ğŸ“ Understanding the message structure for OpenAI's API: a list of dictionaries with roles like \"system,\" \"user,\" and \"assistant.\"\n",
    "- ğŸ”„ Creating a `chat` function to format conversation history for the OpenAI API.\n",
    "- ğŸ’¬ Gradio's `chatinterface` expects a function with specific input parameters (message, history).\n",
    "- ğŸ—£ï¸ Demonstrating how conversation context is maintained by passing the entire history to the LLM with each interaction.\n",
    "- ğŸ”‘ OpenAI converts message structures into tokens, including special tokens, for the LLM to process.\n",
    "- ğŸ§  The LLM learns to interpret these special tokens through training on vast amounts of structured data.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# System message\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for user_msg, assistant_msg in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    print(\"History:\", history)\n",
    "    print(\"Messages:\", messages)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4\"\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in response:\n",
    "        if chunk['choices'][0]['delta'].get('content'):\n",
    "            yield chunk['choices'][0]['delta']['content']\n",
    "\n",
    "# Create Gradio ChatInterface\n",
    "gr.ChatInterface(chat).launch()\n",
    "```\n",
    "\n",
    "# Day 3 - Enhancing Chatbots with Multi-Shot Prompting and Context Enrichment\n",
    "\n",
    "### Summary\n",
    "\n",
    "This session builds upon the previous chatbot example by enhancing the system message to create a more engaging shopping assistant. It demonstrates how to use one-shot and multi-shot prompting to guide the chatbot's responses and introduce dynamic context based on user input. It also explores alternative methods for multi-shot prompting and suggests exercises for further experimentation.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ›ï¸ Enhancing the chatbot's system message to create a helpful shopping assistant.\n",
    "- ğŸ“ Using one-shot and multi-shot prompting to guide the chatbot's tone and provide contextual information.\n",
    "- ğŸ’¬ Demonstrating how to add dynamic context to the conversation based on user input.\n",
    "- ğŸ’¡ Exploring alternative methods for multi-shot prompting, such as user-assistant interaction examples.\n",
    "- ğŸ› ï¸ Suggesting exercises to improve the chatbot, like incorporating a dictionary of store items and prices.\n",
    "- ğŸ”„ Emphasizing the importance of experimentation to find the most effective prompting strategies.\n",
    "- ğŸ§  Showing how to add system messages throughout the conversation to dynamically change context.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Enhanced system message\n",
    "system_message = \"\"\"\n",
    "You are a helpful assistant in a clothes store.\n",
    "You should try to gently encourage the customer to try items on sale.\n",
    "Hats off 60% off. Most other items are 50% off.\n",
    "For example, if the customer says I'm looking to buy a hat, you could reply, wonderful!\n",
    "We have lots of hats, including several part of our sales event.\n",
    "Encourage the customer to buy hats if they're unsure what to get.\n",
    "If the customer asks for shoes, you should respond that shoes are not on sale today.\n",
    "But remind the customer to look at hats.\n",
    "\"\"\"\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    if \"belt\" in message.lower(): # Basic example of dynamic context change\n",
    "        messages.append({\"role\": \"system\", \"content\": \"For added context, the store does not sell belts, but be sure to point out items on sale.\"})\n",
    "    for user_msg, assistant_msg in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4\"\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in response:\n",
    "        if chunk['choices'][0]['delta'].get('content'):\n",
    "            yield chunk['choices'][0]['delta']['content']\n",
    "\n",
    "# Create Gradio ChatInterface\n",
    "gr.ChatInterface(chat).launch()\n",
    "```\n",
    "\n",
    "# Day 3 - Mastering AI Tools: Empowering LLMs to Run Code on Your Machine\n",
    "\n",
    "### Summary\n",
    "\n",
    "This segment recaps the skills acquired, including understanding LLM fundamentals, coding with frontier model APIs, and building AI chatbot UIs. It previews the next topic: \"tools,\" which explores how to empower LLMs to execute code and perform specific functionalities.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸš€ Celebrating the completion of a significant milestone in LLM learning.\n",
    "- ğŸ§  Reviewing the core concepts learned: transformers, tokens, context windows, and API pricing.\n",
    "- ğŸ’» Emphasizing the ability to confidently code with various frontier model APIs.\n",
    "- ğŸ’¬ Highlighting the ease of building interactive AI chatbot UIs using Gradio.\n",
    "- ğŸ› ï¸ Previewing the next topic: \"tools,\" and empowering LLMs to run code.\n",
    "- ğŸ¤« Teasing the revelation of the \"secret sauce\" behind LLM code execution.\n",
    "- ğŸ”® Building anticipation for the next session, promising to demystify the process."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
