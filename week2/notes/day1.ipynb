{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Mastering Multiple AI APIs: OpenAI, Claude, and Gemini for LLM Engineers\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "This lecture introduces the second week of an eight-week program focused on Large Language Model (LLM) engineering. It covers setting up API keys for Anthropic and Google, and expanding the toolkit to include Claude and Gemini alongside GPT-4. The session also outlines the path to mastering LLM technologies, including UI building, agentization, multi-modality, open-source tools, and fine-tuning.\n",
    "\n",
    "### **Highlights**\n",
    "\n",
    "- ğŸ”‘ API Setup: Instructions are given for setting up API keys for Anthropic (Claude) and Google (Gemini), with a note that Google's setup is more complex.\n",
    "- ğŸ’» Expanding Toolkit: Participants will learn to use Claude and Gemini APIs in addition to OpenAI's GPT-4 API.\n",
    "- ğŸ›¤ï¸ Program Roadmap: An overview of the eight-week program's structure, highlighting the progression from basic understanding to advanced LLM applications.\n",
    "- ğŸ› ï¸ Environment Setup: Reminders to configure the JupyterLab environment and manage API keys using a .env file for security.\n",
    "- ğŸ¤ API Integration: Emphasis on writing code that interacts with multiple LLMs, enhancing practical skills.\n",
    "- ğŸš€ Practical Application: The course aims to move quickly into practical applications, building on the foundational knowledge gained in the first week.\n",
    "- ğŸ’¡ Learning Objectives: The goal is to enable participants to confidently use multiple frontier LLMs via their APIs for various business results.\n",
    "\n",
    "# Day 1 - Streaming AI Responses: Implementing Real-Time LLM Output in Python\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "This lecture demonstrates how to use the APIs of OpenAI, Anthropic (Claude), and Google (Gemini) within a JupyterLab environment. It covers setting up API keys, making basic API calls, adjusting parameters like temperature, and streaming responses. The session also includes a fun experiment with LLM-generated jokes and revisits a practical business problem to showcase markdown streaming.\n",
    "\n",
    "### **Highlights**\n",
    "\n",
    "- ğŸ”‘ API Integration: Shows how to connect and use OpenAI, Anthropic, and Google APIs within JupyterLab, emphasizing the differences in setup and usage.\n",
    "- ğŸŒ¡ï¸ Temperature Control: Explains how to adjust the temperature parameter to influence the creativity and randomness of LLM outputs.\n",
    "- ğŸ”„ Streaming Responses: Demonstrates how to stream responses from Claude and OpenAI, including handling markdown formatting for better presentation.\n",
    "- ğŸ­ Joke Experiment: Tests the humor capabilities of different LLMs by asking them to generate jokes for data scientists, comparing their outputs.\n",
    "- ğŸ’¬ System and User Messages: Reinforces the concept of system and user messages in API calls, showcasing their role in guiding LLM behavior.\n",
    "- ğŸ“ Markdown Streaming: Provides a practical example of streaming markdown responses from OpenAI, highlighting the challenges and solutions for proper formatting.\n",
    "- ğŸ¤ API Comparison: Offers a comparative look at the API structures and functionalities of OpenAI, Claude, and Gemini, noting their similarities and differences.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "```python\n",
    "  # OpenAI API call\n",
    "  response = openai.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=prompts\n",
    "  )\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "  # Anthropic (Claude) API call\n",
    "  response = claude.messages.create(\n",
    "      model=\"claude-3.5-sonnet\",\n",
    "      messages=prompts,\n",
    "      system=system_message,\n",
    "      max_tokens=1024\n",
    "  )\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "  # Google (Gemini) API call\n",
    "  model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_message)\n",
    "  response = model.generate_content(user_prompt)\n",
    "```\n",
    "\n",
    "# Day 1 - How to Create Adversarial AI Conversations Using OpenAI and Claude APIs\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "This session demonstrates how to create and manage multi-turn conversations between different LLMs, specifically GPT-4-mini and Claude-3-haiku, by manipulating the structure of message lists sent to their respective APIs. It showcases an adversarial conversation setup where GPT-4-mini is argumentative and Claude-3-haiku is polite, highlighting the importance of context windows and message formatting in LLM interactions.\n",
    "\n",
    "### **Highlights**\n",
    "\n",
    "- ğŸ”„ Constructing multi-turn conversations by managing message lists with system, user, and assistant roles.\n",
    "- ğŸ¤– Setting up an adversarial conversation between GPT-4-mini (argumentative) and Claude-3-haiku (polite).\n",
    "- ğŸ Using Python's `zip` function to iterate through message lists efficiently.\n",
    "- ğŸ› ï¸ Implementing functions to call OpenAI and Anthropic APIs, passing in conversation histories.\n",
    "- ğŸ­ Exploring how different system prompts influence chatbot personalities and interactions.\n",
    "- ğŸ“ Emphasizing the significance of context windows in maintaining conversation flow.\n",
    "- ğŸ§ª Encouraging experimentation by switching chatbot roles and adding Gemini to the conversation.\n",
    "\n",
    "### **Code Examples**\n",
    "\n",
    "```python\n",
    "def gpt(gpt_messages, claude_messages):\n",
    "      messages = [{\"role\": \"system\", \"content\": \"You're a chatbot who's very argumentative. You disagree with everything in the conversation, anything in conversation. And you challenge everything in a snarky way.\"}]\n",
    "      for gpt_msg, claude_msg in zip(gpt_messages, claude_messages):\n",
    "          messages.append({\"role\": \"assistant\", \"content\": gpt_msg})\n",
    "          messages.append({\"role\": \"user\", \"content\": claude_msg})\n",
    "      response = openai.chat.completions.create(model=\"gpt-4-mini\", messages=messages)\n",
    "      return response.choices[0].message.content\n",
    "```\n",
    "\n",
    "```python\n",
    "  def claude(gpt_messages, claude_messages):\n",
    "      messages = []\n",
    "      for gpt_msg, claude_msg in zip(gpt_messages, claude_messages):\n",
    "          messages.append({\"role\": \"user\", \"content\": gpt_msg})\n",
    "          messages.append({\"role\": \"assistant\", \"content\": claude_msg})\n",
    "      messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "      response = claude.messages.create(model=\"claude-3-haiku\", messages=messages, system=\"You're very polite, courteous chatbot. You try to agree with everything the other person says or find common ground. If the other person is argumentative, you try and calm them down and keep chatting.\", max_tokens=1024)\n",
    "      return response.content[0].text\n",
    "\n",
    "```\n",
    "\n",
    "# Day 1 - AI Tools: Exploring Transformers & Frontier LLMs for Developers\n",
    "\n",
    "### Summary\n",
    "\n",
    "This segment recaps the accomplishments of completing the first day of week two, marking 15% progress towards becoming an LM Engineering Master. It highlights the ability to describe Transformers, discuss leading frontier LLMs, and utilize APIs from OpenAI, Anthropic, and Google. The session also previews the next day's focus on Gradio for creating user interfaces for LLMs.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ğŸ‰ Completion of day one, week two, achieving 15% progress in the LM Engineering Master program.\n",
    "- ğŸ§  Ability to describe Transformers, including context windows, tokens, and API costs.\n",
    "- ğŸ—£ï¸ Familiarity with the six leading frontier LLMs.\n",
    "- ğŸ’» Proficiency in using OpenAI's API with streaming, markdown, and JSON.\n",
    "- ğŸ¤ Capability to use Anthropic and Google APIs, understanding the message structure.\n",
    "- ğŸš€ Preview of the next day's session on Gradio for building simple UIs for LLMs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
