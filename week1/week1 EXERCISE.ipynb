{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv()\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ab2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a highly knowledgeable AI tutor with expertise in coding and large language models (LLMs). \n",
    "Your task is to provide clear, concise, and accurate explanations to technical questions.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Explaining the Code**\n",
       "\n",
       "The given code snippet is a Python expression that utilizes a feature called **generator expressions**, which allows you to create generators on-the-fly. Let's break it down:\n",
       "\n",
       "- `yield from`: This keyword is used to delegate to other iterables, allowing them to generate values themselves.\n",
       "\n",
       "- `{book.get(\"author\") for book in books if book.get(\"author\")}`: This part of the expression is a **generator expression**. It creates an iterator that generates values by iterating over the items in the `books` iterable (which seems to be a collection of objects, likely dictionaries).\n",
       "\n",
       "    - `for book in books`: Iterates over each item (`book`) in the `books` collection.\n",
       "    \n",
       "    - `if book.get(\"author\")`: Filters out any item that doesn't have an `\"author\"` key set. This ensures only items with author information are processed.\n",
       "\n",
       "- `book.get(\"author\")`: Extracts the value associated with the `\"author\"` key from each filtered `book` object. If the key is not present, this returns `None`.\n",
       "\n",
       "**What it Does**\n",
       "\n",
       "This code effectively **generates an iterator over book authors**, while filtering out any books without author information.\n",
       "\n",
       "In other words, it generates a sequence of values (`authors`) where each value is the author name extracted from a corresponding book object. However, unlike a traditional for loop which consumes all resources (memory), this expression uses memory efficiently because it only stores one book object at a time in memory, making it more suitable for large datasets.\n",
       "\n",
       "**Why**\n",
       "\n",
       "This code is useful when you want to iterate over books and perform an action on each author without storing the entire list of authors in memory. The `yield from` keyword helps achieve this by avoiding excessive memory usage.\n",
       "\n",
       "Here's an example use case:\n",
       "\n",
       "```python\n",
       "# Let's assume 'books' is a list of dictionaries with book information.\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author 1\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author 2\"},\n",
       "    # Ignore the book without an author...\n",
       "]\n",
       "\n",
       "for book in books:\n",
       "    if book.get(\"author\"):\n",
       "        print(book[\"author\"])\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "reply = response['message']['content']\n",
    "display(Markdown(reply))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
