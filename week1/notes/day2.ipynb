{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering LLM Engineering: Key Skills and Tools for AI Development\n",
    "\n",
    "### Summary\n",
    "\n",
    "Congratulations on completing the first day of the course! Today, we will discuss the steps to becoming an LLM engineer and explore frontier models. This practical course will cover theory and involve building commercial projects.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ü¶ô You can run models locally using a llama and call OpenAI's API for frontier models.\n",
    "- üß† Understanding the difference between a system and a user prompt is key.\n",
    "- üõ†Ô∏è Familiarize yourself with various LM models, architectures, and selecting the right one.\n",
    "- üì¶ Explore tools like Hugging Face, Lange chain, Gradio, Weights and Biases, and Modal for deployment.\n",
    "- üíº Learn techniques to solve business problems with AI, including using APIs, fine-tuning, and full AI solutions.\n",
    "- üêç Prerequisite is beginner to intermediate level Python, with resources available to help you progress.\n",
    "- ü§ù Engage with the course content by following along with coding, completing exercises, and sharing your code on GitHub.\n",
    "\n",
    "# Understanding Frontier Models: GPT, Claude, and Open Source LLMs\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this session, we discussed frontier models, including closed source models like GPT and Claude, as well as open source models like llama and Mistral. We also covered different ways to interact with these models, such as through chat interfaces, cloud APIs, and running the models locally.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üí° Frontier models refer to cutting-edge models pioneering what is possible today.\n",
    "    - GPT from OpenAI\n",
    "    - Claude from Antropic\n",
    "    - Gemini from Google\n",
    "    - Command R from Cohere\n",
    "    - Perplexity\n",
    "- üíª Closed source frontier models like GPT, Claude, and Gemini are known for their scale and power.\n",
    "    - Llama from Meta\n",
    "    - Mixtral from Mistral\n",
    "    - Qwen from Alibaba Cloud\n",
    "    - Gemma from Google\n",
    "    - Phi from Microsoft\n",
    "- üåê Open source models like llama and Mistral offer alternatives to closed source models.\n",
    "- ü§ñ Different approaches to using models include chat interfaces, cloud APIs, and running models locally.\n",
    "- üì¶ Hugging Face provides access to model code for granular control, while llama CPW offers optimized C++ code for local execution.\n",
    "- üß† Understanding the landscape of model usage is crucial for effective utilization in various contexts.\n",
    "- üöÄ The session concluded with an exercise involving olama to apply the concepts discussed.\n",
    "\n",
    "# How to Use Ollama for Local LLM Inference: Python Tutorial with Jupyter\n",
    "\n",
    "```python\n",
    "# Function to fetch and extract the website's textual content\n",
    "def summarize_website(url, max_length=1000):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    # Extract text from <p> tags\n",
    "    paragraphs = soup.find_all('p')\n",
    "    content = ' '.join(p.get_text() for p in paragraphs)\n",
    "    # Limit text length if it's too long\n",
    "    if len(content) > max_length:\n",
    "        content = content[:max_length] + '...'\n",
    "    return content\n",
    "\n",
    "# Get the website URL from the user\n",
    "url = input(\"Enter website URL: \")\n",
    "\n",
    "# Extract website content\n",
    "website_content = summarize_website(url)\n",
    "\n",
    "# Build the prompt instructing Llama 3.2 to summarize the website content\n",
    "summarize_prompt = f\"Please summarize the following website content:\\n\\n{website_content}\"\n",
    "# Create a new messages list for this task\n",
    "summarize_messages = [{\"role\": \"user\", \"content\": summarize_prompt}]\n",
    "\n",
    "# Prepare payload for the Ollama API call\n",
    "payload = {\n",
    "    \"model\": MODEL,\n",
    "    \"messages\": summarize_messages,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "# Post the request to the local Ollama server and print out the summary\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])\n",
    "```\n",
    "\n",
    "The website appears to be a personal blog or portfolio of Eda AYDIN, a Data Analyst/Data Scientist with expertise in Artificial Intelligence (AI) and Machine Learning. She describes herself as an advocate for innovation in healthcare and sustainability. The content suggests that she explores the intersection of data, healthcare, and technology, aiming to provide meaningful insights from complex information.\n",
    "\n",
    "The website invites visitors to explore Eda's work experience, projects, and ideas, showcasing how AI is shaping the future of medicine and how data can drive impactful change.\n",
    "\n",
    "# Hands-On LLM Task: Comparing OpenAI and Ollama for Text Summarization\n",
    "\n",
    "### Summary\n",
    "\n",
    "Day two concludes with hands-on experience in comparing OpenAI and Ollama for text summarization. Next time, participants will work with Frontier models to understand the differences between them.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üéâ Day two wraps up with building a solution for text summarization.\n",
    "- üß† Participants will gain hands-on experience with Frontier models to develop a better intuition for their differences.\n",
    "- üöÄ The latest versions of the models will be used, highlighting both strengths and areas where they struggle."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
