{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737e0bfb",
   "metadata": {},
   "source": [
    "# Day 1 - Hugging Face Tutorial: Exploring Open-Source AI Models and Datasets\n",
    "\n",
    "### Summary\n",
    "\n",
    "This session enthusiastically welcomes learners back to week three of their LLM engineering journey, transitioning from UI building with Gradio to exploring the open-source world of Hugging Face. The session recaps prior knowledge in Transformers, API usage, and AI assistant creation, then introduces the Hugging Face platform, its libraries, and Google Colab for running code with GPUs. It also previews upcoming topics like LM selection, RAG, and fine-tuning using Hugging Face tools.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ü§ó Introduction to Hugging Face as a comprehensive open-source resource for the data science community.\n",
    "- ‚öôÔ∏è Overview of the Hugging Face platform, including access to over 800,000 models, 200,000 datasets, and Spaces for app deployment.\n",
    "- üöÄ Mention of Google Colab as an environment for running code with GPU access, relevant for the course.\n",
    "- üìö Explanation of key Hugging Face libraries such as the Hub for downloading/uploading, Datasets for accessing data, and Transformers as a central library for LLMs.\n",
    "- üß† Introduction to more advanced libraries like Peft for parameter-efficient fine-tuning (including LoRA), TRL for Transformer Reinforcement Learning (reward modeling, PPO, SFT), and Accelerate for distributed training and inference.\n",
    "- üõ†Ô∏è Highlight of Spaces, often built with Gradio or Streamlit, for sharing open-source AI applications and leaderboards for evaluating LLMs.\n",
    "- üóìÔ∏è Roadmap of the course, including upcoming weeks focusing on LM selection, RAG (Retrieval-Augmented Generation), and fine-tuning both frontier and open-source models.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "- üíª While specific code examples aren't provided in this introductory segment, the mention of Hugging Face libraries like `transformers`, `datasets`, and `accelerate` implies the use of Python code for interacting with these tools. For instance, accessing a pre-trained model using the `transformers` library would involve code similar to:\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) 1 \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name) 2 \n",
    "```\n",
    "\n",
    "```python\n",
    "üíæ Similarly, accessing datasets using the `datasets` library might involve:\n",
    "```python\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "```\n",
    "\n",
    "# Day 1 - Exploring HuggingFace Hub: Models, Datasets & Spaces for AI Developers\n",
    "\n",
    "### Summary\n",
    "\n",
    "This part of the session provides a guided tour of the Hugging Face platform. It covers signing up for an account, navigating the main sections (Models, Datasets, and Spaces), and highlights key functionalities such as searching, filtering, exploring model details, accessing code examples, and understanding the underlying Git repository structure. The session also showcases the vast collection of datasets and the diverse applications available on Spaces, including leaderboards and fun AI tools. Finally, it emphasizes the importance of creating an access token for programmatic interaction with the Hugging Face Hub.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üîë Instructions on how to sign up for a free Hugging Face account and navigate the main interface.\n",
    "- ü§ñ Exploration of the \"Models\" section, showcasing the vast number of available open-source models, filtering options (e.g., by name like \"llama\" or \"gemma\"), and accessing model details, code examples, and file versions (backed by Git).\n",
    "- üíæ Overview of the \"Datasets\" section, highlighting the extensive collection of data and demonstrating a search for product price datasets, including a specific comprehensive dataset that will be used later in the course.\n",
    "- üöÄ Introduction to \"Spaces\" as a platform for running and sharing AI applications, many built with Gradio or Streamlit, including examples like the AI Comic Factory and an image garment application. It also mentions leaderboards for evaluating LLMs.\n",
    "- üë§ A look at the user's profile, showing personal models, datasets (which can be public or private), and a custom-built LLM battle game as an example of a Streamlit application deployed on Spaces.\n",
    "- ‚öôÔ∏è Crucial steps for setting up access tokens in the user settings, emphasizing the need to create a new token with read and write permissions for use in environments like Jupyter to interact with the Hugging Face Hub.\n",
    "- üó∫Ô∏è Encouragement for viewers to sign up, create an API key, and explore the models, datasets, and spaces available on the Hugging Face platform.\n",
    "\n",
    "# Day 1 - Intro to Google Colab: Cloud Jupyter Notebooks for Machine Learning\n",
    "\n",
    "### Summary\n",
    "\n",
    "This section introduces Google Colaboratory (Colab) as a primary resource for running Jupyter notebooks in the cloud. It highlights Colab's benefits, including its widespread use, ease of sharing and collaboration (similar to Google Docs), integration with Google services, and the option to utilize CPUs or GPUs for running code. The discussion covers different runtime options, from CPU-based to various GPU specifications, and assures that the course activities will generally be manageable within the free tier or with minimal cost. The segment concludes by transitioning to a practical look at the Colab environment.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- ‚òÅÔ∏è Introduction to Google Colab as a cloud-based environment for running Jupyter notebooks.\n",
    "- ü§ù Emphasis on Colab's ease of sharing and real-time collaboration, similar to other Google Suite applications.\n",
    "- ‚öôÔ∏è Explanation of the different runtime options available in Colab, including CPU-only and various tiers of GPU-enabled virtual machines.\n",
    "- üí∞ Assurance that the course is designed to be completed using free Colab resources, with potential minimal costs only for more intensive tasks like prolonged training on high-end GPUs.\n",
    "- üîó Mention of alternatives to Google Colab, suggesting that while Colab will be the primary platform used and shared, other similar services can also be utilized.\n",
    "- üíæ Integration with Google Drive for easy access to personal data and resources within the Colab environment.\n",
    "- üöÄ Transition to a practical demonstration of the Google Colab interface to familiarize learners with its features.\n",
    "\n",
    "# Day 1 - Hugging Face Integration with Google Colab: Secrets and API Keys Setup\n",
    "\n",
    "### Summary\n",
    "\n",
    "This session provides a hands-on introduction to Google Colab, guiding users through the initial setup, interface overview, and key features. It covers accessing Colab, creating notebooks, selecting runtime types (CPU and different GPUs like T4 and A100), and connecting to a virtual machine. The session also demonstrates how to view system resources, manage API keys securely using the secrets feature, utilize the file browser, and share notebooks for collaboration. Practical examples of running Python code and checking GPU information are also shown.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üíª Accessing Google Colab and creating a new notebook, highlighting its similarity to Jupyter notebooks and integration with Google Drive.\n",
    "- ‚öôÔ∏è Understanding and changing runtime types, including CPU, T4 GPU (available on the free tier), and the more powerful A100 GPU.\n",
    "- üîë Utilizing the \"Secrets\" feature to securely store and access API keys for various services like Anthropic, OpenAI, and Hugging Face.\n",
    "- üíæ Exploring the file browser for temporary file storage and the ability to interact with the connected virtual machine's file system.\n",
    "- üìä Viewing system resources (RAM, disk space, GPU) to understand the capabilities of the chosen runtime.\n",
    "- ü§ù Sharing notebooks for collaborative work using a familiar Google Drive-like interface with different permission settings.\n",
    "- üöÄ Demonstrating basic Python code execution and using `!nvidia-smi` to inspect GPU details, such as name and memory usage.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "- üêç Running a basic print statement in a Colab code cell:\n",
    "    \n",
    "    ```python\n",
    "    print(\"hello Data Science World\")\n",
    "    \n",
    "    ```\n",
    "    \n",
    "- üîë Accessing secrets stored in Colab as environment variables:\n",
    "    \n",
    "    ```python\n",
    "    import os\n",
    "    ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    HUGGINGFACE_TOKEN = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "    \n",
    "    ```\n",
    "    \n",
    "- üõ†Ô∏è Checking GPU information using a shell command:\n",
    "    \n",
    "    ```python\n",
    "    !nvidia-smi\n",
    "    \n",
    "    ```\n",
    "    \n",
    "\n",
    "# Day 1 - Mastering Google Colab: Run Open-Source AI Models with Hugging Face\n",
    "\n",
    "### Summary\n",
    "\n",
    "This concluding part of the session summarizes the progress made, highlighting the learner's readiness to embark on their open-source journey with knowledge of Hugging Face and Google Colab. It provides a compelling example of using the Flux model in Colab for text-to-image generation, demonstrating the ease of leveraging cloud GPUs. The session then previews the next steps, which include learning to run open-source models using Hugging Face's different API levels, starting with pipelines for various AI tasks like text, image, and audio generation.\n",
    "\n",
    "### Highlights\n",
    "\n",
    "- üñºÔ∏è A visual example of text-to-image generation using the Flux model in Google Colab, showcasing the potential of open-source models and cloud GPUs.\n",
    "- üöÄ Reinforcement of the learner's preparedness to begin working with open-source tools, having gained familiarity with Hugging Face and Google Colab.\n",
    "- üó∫Ô∏è A look ahead at the next session, which will cover running open-source models using Hugging Face's APIs.\n",
    "- ‚öôÔ∏è Introduction to the concept of different API levels within Hugging Face and a focus on the first one: pipelines.\n",
    "- üí° Preview of using pipelines for various AI tasks, including generating text, images, and audio from open-source models.\n",
    "- ü§© Expression of anticipation for the upcoming practical applications of open-source models.\n",
    "\n",
    "### Code Examples\n",
    "\n",
    "- üíª The transcript shows a screenshot of Hugging Face code run in Google Colab to generate an image using the Flux model. While the exact code isn't provided in text format, it would likely involve using the `transformers` library and the `pipeline` function for the \"text-to-image\" task, specifying the Flux model. A conceptual example might look like this:\n",
    "Python\n",
    "    \n",
    "    ```python\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    image_generator = pipeline(\"text-to-image\", model=\"BlackForestAI/Flux\")\n",
    "    prompt = \"a futuristic class full of students learning AI coding in the surreal style of Dall-E\"\n",
    "    image = image_generator(prompt=prompt)\n",
    "    image[0].save(\"futuristic_ai_class.png\")\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
