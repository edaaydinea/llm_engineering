{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248564c0",
   "metadata": {},
   "source": [
    "# Day 2 - Hugging Face Transformers: Using Pipelines for AI Tasks in Python\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "This content introduces the Hugging Face Transformers library, highlighting its two API levels for interacting with models: high-level \"pipelines\" for easy, everyday inference tasks, and lower-level APIs involving tokenizers and models for more detailed control, training, or fine-tuning. The primary focus is on pipelines, which simplify the use of pre-trained models for a variety of tasks like text generation, sentiment analysis, and image generation with minimal code, making advanced AI capabilities highly accessible.\n",
    "\n",
    "### **Highlights**\n",
    "\n",
    "- ‚ú® **Two API Levels in Hugging Face Transformers:** The library offers a high-level API (Pipelines) for quick and easy use of models for standard tasks, and lower-level APIs (Tokenizers, Models) for users needing more control, customization, or to train/fine-tune models.\n",
    "    - **Relevance:** This dual structure caters to both beginners or those needing rapid prototyping (Pipelines) and advanced users or researchers requiring granular control (lower-level APIs), democratizing access to complex models.\n",
    "- üöÄ **Pipelines for Simplified Inference:** Hugging Face Pipelines allow users to perform various inference tasks (like sentiment analysis, text generation, translation) with just a few lines of code, abstracting away the complexity of model loading and preprocessing.\n",
    "    - **Relevance:** Extremely useful for data scientists and developers to quickly integrate SOTA NLP and multimodal models into applications without deep knowledge of the underlying model architecture.\n",
    "- üìã **Variety of Tasks Supported by Pipelines:** Pipelines can execute a wide range of pre-defined tasks including sentiment analysis, text classification, named entity recognition (NER), question answering, summarization, translation, text generation, image generation, and audio processing.\n",
    "    - **Relevance:** Provides a versatile toolkit for tackling common AI problems across different domains (e.g., customer feedback analysis with sentiment analysis, content creation with text generation, information extraction with NER).\n",
    "- üíª **Accessibility through Google Colab:** The content emphasizes using Google Colab for running code and interacting with Hugging Face, indicating an accessible environment for experimentation and learning.\n",
    "    - **Relevance:** Lowers the barrier to entry for experimenting with powerful AI models, as Colab provides free compute resources and a pre-configured environment.\n",
    "\n",
    "### **Conceptual Understanding**\n",
    "\n",
    "- **Two API Levels in Hugging Face Transformers**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - Understanding the two API levels allows users to choose the right tool for their needs. Pipelines are for quick application, while lower-level APIs offer control for research, custom model development, and fine-tuning.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - A startup might use pipelines for a quick MVP of a feature (e.g., a sentiment analysis tool for customer reviews). A research institution might use the lower-level APIs to develop a novel model architecture for a specific scientific text understanding task.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Software abstraction, API design, model inference, model training, transfer learning, MLOps (for deploying and managing models accessed via these APIs).\n",
    "- **Pipelines for Simplified Inference**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - Pipelines drastically reduce the boilerplate code needed to use pre-trained models, making it faster and easier to get from model selection to obtaining results. This accelerates development and experimentation.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - A content creator could use a text generation pipeline to draft articles. A support team could use a question-answering pipeline to quickly find answers in documentation. A marketing team could use an image generation pipeline for ad creatives.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Pre-trained models, Hugging Face Hub (as a source of models for pipelines), model deployment, rapid prototyping, no-code/low-code AI platforms.\n",
    "- **Variety of Tasks Supported by Pipelines**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - Knowing the range of available tasks helps in identifying off-the-shelf solutions for common problems without needing to build models from scratch, saving significant time and resources.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - **Sentiment analysis:** Analyzing product reviews or social media comments in finance or retail.\n",
    "        - **Named Entity Recognition (NER):** Extracting key information like names of people, organizations, and locations from legal documents or news articles in legal tech or journalism.\n",
    "        - **Summarization:** Creating digests of long reports for business intelligence or news aggregation.\n",
    "        - **Translation:** Breaking language barriers in global customer support or international collaboration.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Natural Language Processing (NLP), Computer Vision (for image generation), Audio Processing, specific model architectures suited for each task (e.g., BERT for NER, GPT for text generation, T5 for translation/summarization).\n",
    "- **Accessibility through Google Colab**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - It highlights that powerful AI tools are not limited to those with high-end hardware. Cloud-based environments like Colab provide the necessary computational resources, making AI more inclusive.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - Students can learn and experiment with SOTA models without personal investment in GPUs. Researchers can collaborate easily. Small businesses can explore AI solutions without upfront infrastructure costs.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Cloud computing, Jupyter notebooks, GPU acceleration, collaborative coding platforms, open-source software.\n",
    "\n",
    "### **Reflective Questions**\n",
    "\n",
    "- How can I apply this concept in my daily data science work or learning?\n",
    "    - You can use Hugging Face pipelines to quickly test hypotheses with different pre-trained models for tasks like text classification or summarization on new datasets, or to add intelligent features to prototype applications with minimal coding effort.\n",
    "- Can I explain this concept to a beginner in one sentence?\n",
    "    - Hugging Face pipelines let you use powerful pre-trained AI models for common tasks like understanding text or generating images using just a couple of lines of code, like a ready-to-use toolkit for AI.\n",
    "- Which type of project or domain would this concept be most relevant to?\n",
    "    - This would be highly relevant for projects involving Natural Language Processing (like chatbots, content analysis tools, translation services) and increasingly for multimodal projects (combining text, images, audio) across various domains including customer service, content creation, healthcare informatics, and finance.\n",
    "\n",
    "# Day 2 - Hugging Face Pipelines: Simplifying AI Tasks with Transformers Library\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "This content provides a hands-on demonstration of Hugging Face pipelines within a Google Colab environment, showcasing their simplicity and power for various AI tasks. It emphasizes how these high-level APIs allow users to perform complex operations like sentiment analysis, named entity recognition, text generation, image generation (using the Diffusers library), and audio synthesis with minimal code, thereby making open-source models highly accessible for production and experimentation.\n",
    "\n",
    "### **Highlights**\n",
    "\n",
    "- üõ†Ô∏è **Practical Pipeline Instantiation:** Demonstrates the core two-step process: first, initializing a pipeline by specifying a task string (e.g., `\"sentiment-analysis\"`, `\"text-generation\"`), and then calling the pipeline object with input data to get results.\n",
    "    - **Relevance:** This simplifies the use of complex models down to a few lines of Python, significantly lowering the barrier to entry for applying AI in various data science workflows and applications.\n",
    "- ‚öôÔ∏è **Essential Library Installation:** Highlights the necessary libraries: `transformers` (core), `datasets` (for accessing Hugging Face datasets), and `diffusers` (for image generation models). The use of `!pip install -q <library>` in Colab is shown.\n",
    "    - **Relevance:** Knowing these foundational libraries is crucial for setting up the environment to work with Hugging Face models for NLP, image, and audio tasks.\n",
    "- GPU **Leveraging GPU for Performance:** Shows how to specify `device=\"cuda\"` when creating a pipeline to ensure models run on available GPU resources, significantly speeding up inference.\n",
    "    - **Relevance:** Critical for efficient processing, especially with larger models or in production environments, as GPUs offer substantial speedups for deep learning computations.\n",
    "- üìù **Diverse NLP Tasks with Pipelines:** Walks through concrete examples of pipelines for sentiment analysis, named entity recognition (NER), question answering (with context), text summarization (with length controls), translation, and zero-shot classification.\n",
    "    - **Relevance:** Illustrates the versatility of pipelines for a wide array of common NLP problems, useful in areas like customer feedback analysis, information extraction from documents, automated content creation, and multilingual applications.\n",
    "- üñºÔ∏è **Image Generation with Diffusers & Stable Diffusion:** Explains that image generation uses the `diffusers` library, showcasing an example with Stable Diffusion to generate images from text prompts, noting the need for specific data types and GPU usage.\n",
    "    - **Relevance:** Opens up possibilities for creative content generation, data augmentation, or generating visual aids, applicable in marketing, design, and research.\n",
    "- üó£Ô∏è **Audio Generation (Text-to-Speech):** Demonstrates using the `\"text-to-speech\"` pipeline with a specific model (`microsoft/speecht5_tts`) and loading speaker embeddings for voice customization, then saving the output as a `.wav` file.\n",
    "    - **Relevance:** Useful for creating voice assistants, audiobook narration, accessibility features in applications, and generating spoken feedback in various systems.\n",
    "- üí° **Model Selection and Default Behavior:** Points out that while pipelines use default models for tasks if none are specified, users can (and are encouraged to) pass a `model` argument to select specific models from the Hugging Face Hub.\n",
    "    - **Relevance:** Allows users to choose models based on size, performance, language, or specific capabilities, tailoring the pipeline to their exact needs.\n",
    "\n",
    "### **Conceptual Understanding**\n",
    "\n",
    "- **Practical Pipeline Instantiation**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - It's the fundamental mechanism for using Hugging Face's high-level API, making powerful models accessible without needing to manage tokenization, model loading, and post-processing manually.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - A developer can quickly integrate a summarization feature into a news app, or a researcher can rapidly test different language models for a sentiment analysis task on a new dataset.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - API design, software abstraction, inference endpoints, pre-trained models, Hugging Face Hub.\n",
    "- **Essential Library Installation**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - These libraries provide the core functionalities. `transformers` for models and pipelines, `datasets` for data handling, and `diffusers` specifically for diffusion models (common in image generation).\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - Any project leveraging Hugging Face models will start with installing these. Setting up a correct environment is the first step in any data science or ML project.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Python package management (pip), virtual environments, software dependencies, MLOps (environment setup).\n",
    "- **Leveraging GPU for Performance**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - Deep learning models are computationally intensive. Using a GPU (via CUDA for NVIDIA GPUs) dramatically reduces inference (and training) time, making a practical difference in usability.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - Real-time applications like live translation or interactive chatbots require fast responses, achievable with GPU acceleration. Batch processing large datasets for analysis is also made feasible.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Hardware acceleration, parallel computing, CUDA, deep learning frameworks (PyTorch, TensorFlow), cloud computing (GPU instances).\n",
    "- **Diverse NLP Tasks with Pipelines**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - Showcases the breadth of problems solvable with pre-trained models through a unified interface, allowing users to switch between tasks easily.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - **Sentiment Analysis:** Gauge public opinion on products/services (finance, marketing).\n",
    "        - **NER:** Extract entities from patient records (healthcare) or legal contracts (legal-tech).\n",
    "        - **QA:** Build FAQ bots from company documents (customer support).\n",
    "        - **Summarization:** Condense articles for quick reading (media, research).\n",
    "        - **Translation:** Enable multilingual communication (global business).\n",
    "        - **Zero-shot Classification:** Categorize text without prior training examples (flexible content tagging).\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Natural Language Processing, specific model architectures (BERT, T5, GPT), transfer learning.\n",
    "- **Image Generation with Diffusers & Stable Diffusion**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - Introduces the capability to generate novel images from text, a significant advancement in creative AI and multimodal applications. `diffusers` is Hugging Face's dedicated library for these models.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - Creating custom illustrations for articles, generating synthetic data for training computer vision models, designing marketing visuals, or artistic exploration.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Generative AI, diffusion models, multimodal AI, computer vision, prompt engineering.\n",
    "- **Audio Generation (Text-to-Speech)**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - Extends AI capabilities to the auditory domain, enabling applications that can speak or generate audio content dynamically.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - Developing voiceovers for videos, creating accessibility tools for visually impaired users, building interactive voice response (IVR) systems, or generating personalized audio messages.\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Speech synthesis, Text-to-Speech (TTS) models, speaker embeddings, audio processing, multimodal AI.\n",
    "- **Model Selection and Default Behavior**\n",
    "    - **Why is this concept important to know or understand?**\n",
    "        - While defaults are convenient, real-world applications often require specific model characteristics (e.g., language-specific, size-constrained for edge devices, or state-of-the-art for accuracy). Knowing how to select models is key.\n",
    "    - **How does it connect with real-world tasks, problems, or applications?**\n",
    "        - Choosing a multilingual translation model for a global platform, or a smaller, faster sentiment model for a mobile app. Selecting a domain-specific model (e.g., BioBERT for biomedical text).\n",
    "    - **What other concepts, techniques, or areas is this related to?**\n",
    "        - Hugging Face Hub, model cards (for understanding model specifics), transfer learning, model optimization, MLOps (model versioning and selection).\n",
    "\n",
    "### **Code Examples**\n",
    "\n",
    "The transcript describes the following code patterns and commands:\n",
    "\n",
    "**1. Installation of Libraries:**\n",
    "\n",
    "**Python**\n",
    "\n",
    "```python\n",
    "!pip install -q transformers datasets diffusers\n",
    "\n",
    "```\n",
    "\n",
    "This command is used in a Colab environment to quietly install the `transformers`, `datasets`, and `diffusers` libraries.\n",
    "\n",
    "**2. General Pipeline Usage:**\n",
    "\n",
    "**Python**\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the pipeline for a specific task\n",
    "# Example: Sentiment Analysis\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Optionally, specify a model and run on GPU\n",
    "# classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=\"cuda\")\n",
    "\n",
    "# Call the pipeline with input\n",
    "result = classifier(\"I am super excited to be on the way to LLM mastery.\")\n",
    "print(result)\n",
    "\n",
    "# Example: Named Entity Recognition\n",
    "ner_pipeline = pipeline(\"ner\", device=\"cuda\")\n",
    "text_for_ner = \"Barack Obama was the 44th president of the United States.\"\n",
    "ner_results = ner_pipeline(text_for_ner)\n",
    "print(ner_results)\n",
    "\n",
    "# Example: Question Answering\n",
    "qa_pipeline = pipeline(\"question-answering\", device=\"cuda\")\n",
    "context = \"Barack Obama was the 44th president of the United States.\"\n",
    "question = \"Who was the 44th president of the US?\"\n",
    "qa_result = qa_pipeline(question=question, context=context)\n",
    "print(qa_result)\n",
    "\n",
    "# Example: Summarization\n",
    "summarizer = pipeline(\"summarization\", device=\"cuda\")\n",
    "long_text = \"The Hugging Face Transformers library is amazing because it provides easy access to thousands of pre-trained models...\" # (input long text)\n",
    "summary = summarizer(long_text, min_length=5, max_length=20)\n",
    "print(summary)\n",
    "\n",
    "# Example: Translation\n",
    "translator = pipeline(\"translation_en_to_fr\", device=\"cuda\") # Example: English to French\n",
    "text_to_translate = \"The data scientists were truly amazed by the power and simplicity of the Hugging Face pipeline API.\"\n",
    "translation = translator(text_to_translate)\n",
    "print(translation)\n",
    "\n",
    "# Example: Zero-shot Classification\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", device=\"cuda\")\n",
    "text_to_classify = \"Hugging Face Transformers library is amazing.\"\n",
    "candidate_labels = [\"technology\", \"sports\", \"politics\"]\n",
    "classification_result = zero_shot_classifier(text_to_classify, candidate_labels=candidate_labels)\n",
    "print(classification_result)\n",
    "\n",
    "# Example: Text Generation\n",
    "text_generator = pipeline(\"text-generation\", device=\"cuda\")\n",
    "prompt = \"If there's one thing I want you to remember about using Huggingface pipelines, it's\"\n",
    "print(result[0]['generated_text'])\n",
    "\n",
    "```\n",
    "\n",
    "3. Image Generation (using Diffusers):\n",
    "\n",
    "Conceptual structure based on description:\n",
    "\n",
    "**Python**\n",
    "\n",
    "```python\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch # for dtype\n",
    "\n",
    "# Load the model (this will download if not cached)\n",
    "image_pipeline = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "prompt = \"A class of data scientists learning about AI in the surreal style of Salvador Dali\"\n",
    "image = image_pipeline(prompt).images[0]\n",
    "# image.save(\"generated_image.png\") # To save the image\n",
    "\n",
    "```\n",
    "\n",
    "4. Audio Generation (Text-to-Speech):\n",
    "\n",
    "Conceptual structure based on description:\n",
    "\n",
    "**Python**\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset # To load speaker embeddings\n",
    "import soundfile as sf # To save audio file\n",
    "\n",
    "# Initialize text-to-speech pipeline\n",
    "tts_pipeline = pipeline(\"text-to-speech\", model=\"microsoft/speecht5_tts\", device=\"cuda\")\n",
    "\n",
    "# Load speaker embeddings (example from the transcript context)\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0) # Example speaker\n",
    "\n",
    "text_to_speak = \"Hi to an artificial intelligence engineer on the way to mastery.\"\n",
    "speech_output = tts_pipeline(text_to_speak, forward_params={\"speaker_embeddings\": speaker_embeddings})\n",
    "\n",
    "# Save the audio output\n",
    "sf.write(\"output_speech.wav\", speech_output[\"audio\"], samplerate=speech_output[\"sampling_rate\"])\n",
    "Audio(\"speech.wav\")\n",
    "\n",
    "```\n",
    "\n",
    "*(Note: The exact code for loading speaker embeddings and saving audio might have slight variations based on the specific libraries and versions, the above is a conceptual representation from the transcript.)*\n",
    "\n",
    "### **Reflective Questions**\n",
    "\n",
    "- How can I apply this concept in my daily data science work or learning?\n",
    "    - You can rapidly prototype solutions for various NLP, image, or audio tasks (e.g., analyzing customer reviews, generating placeholder images, creating voice responses) using pipelines with minimal setup, allowing quick iteration and experimentation with different pre-trained models from the Hugging Face Hub.\n",
    "- Can I explain this concept to a beginner in one sentence?\n",
    "    - Hugging Face pipelines are like easy-to-use shortcuts that let you tap into powerful pre-trained AI models for tasks like understanding text, creating images, or generating speech, all with just a few lines of code.\n",
    "- Which type of project or domain would this concept be most relevant to?\n",
    "    - These concepts are highly relevant for projects in Natural Language Processing (chatbots, text analytics, translation services), creative AI (content generation, art), accessibility tools (text-to-speech), and any application requiring quick integration of sophisticated AI capabilities across domains like marketing, healthcare, finance, and education.\n",
    "\n",
    "# Day 2 - Mastering HuggingFace Pipelines: Efficient AI Inference for ML Tasks\n",
    "\n",
    "### Summary\n",
    "\n",
    "This lecture serves as a checkpoint, acknowledging the learner's progress in LM engineering, including coding with frontier models, building multimodal AI assistants, and using Hugging Face pipelines for various inference tasks. It emphasizes the cumulative nature of these skills and transitions to the next topic: delving into the lower-level Transformers API, specifically focusing on tokenizers, the process of converting text to tokens (and back), special tokens, and chat templates, which are foundational for deeper LLM understanding."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
